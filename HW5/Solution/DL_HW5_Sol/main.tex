\documentclass[12pt]{article}
\input{etc/cmd}

\begin{document}
\fontsize{12pt}{14pt}\selectfont

\input{etc/head}

\centering {\fontsize{18}{22}\selectfont \textbf{مهلت تحویل : 1404/03/06 }}\\
{\fontsize{14}{22}\selectfont \textbf{لطفا به نکات موجود در سند قوانین انجام و تحویل تمرین ها دقت فرمایید. }}

\begin{enumerate}

    \section*{سوالات تئوری}
    \item \includegraphics[width=1cm]{figs/Forbidden_AI.jpg}
    مقاله \href{https://proceedings.neurips.cc/paper_files/paper/2023/file/299a08ee712d4752c890938da99a77c6-Paper-Conference.pdf}{\lr{Composing Parameter-Efficient Modules with Arithmetic Operations}} را مطالعه کنید و به سوالات زیر پاسخ دهید(۱۵ نمره):
    \begin{enumerate}
        \item با توجه به مقاله، هدف اصلی استفاده از روش‌های \lr{PEFT} در مدل‌های زبانی چیست؟ همچنین دو روش \lr{PEFT} بررسی‌شده در این مقاله کدام‌اند و ویژگی‌های متمایز آن‌ها نسبت به روش‌های سنتی \lr{finetuning} چیست؟
        
        \textcolor{blue}{هدف اصلی استفاده از روش‌های \lr{PEFT}، تطبیق \lr{LLM}  های از پیش آموزش‌دیده با وظایف جدید، بدون نیاز به بازآموزی یا تغییر تمام پارامترهای مدل اصلی است. در روش سنتی تنظیم دقیق کامل، کل پارامترهای مدل برای وظیفه جدید به‌روزرسانی می‌شوند که این امر منجر به مشکلاتی مانند هزینه محاسباتی بالا، نیاز به حافظه زیاد، فراموشی فاجعه‌بار می شود.\\
        روش‌های \lr{PEFT} با ثابت نگه داشتن پارامترهای مدل اصلی و افزودن تعداد بسیار کمی پارامتر قابل آموزش (در قالب یک ماژول کوچک)، این مشکلات را حل می‌کنند. این رویکرد، فرآیند تطبیق را بسیار کارآمدتر و سبک‌تر می‌سازد.\\
        این مقاله به طور خاص دو روش محبوب \lr{PEFT} را بررسی و با هم مقایسه می‌کند:
        \begin{itemize}
            \item \lr{LoRA}:
            \begin{itemize}
                \item این روش به جای تغییر مستقیم وزن‌های سنگین مدل، دو ماتریس کوچک و کم‌رتبه \LTRfootnote{Low-Rank} را به لایه‌های مدل تزریق می‌کند. در حین آموزش، فقط این ماتریس‌های کوچک به‌روزرسانی می‌شوند. حاصل‌ضرب این دو ماتریس، تغییری را که در حالت تنظیم دقیق کامل باید در وزن اصلی ایجاد می‌شد، «شبیه‌سازی» یا «تقریب» می‌زند.
                \item ویژگی متمایز: تعداد پارامترهای قابل آموزش در \lr{LoRA} بسیار کمتر از تنظیم دقیق کامل است و به اندازه مدل اصلی بستگی ندارد، بلکه به  رتبه \LTRfootnote{rank} انتخابی برای ماتریس‌ها وابسته است.
            \end{itemize}
            \item  \lr{(IA)³}:
            \begin{itemize}
                \item این روش حتی از \lr{LoRA} هم پارامتر-کارآمدتر است \lr{(IA)³} به جای افزودن ماتریس‌های جدید، بردارهای کوچکی را برای مقیاس‌دهی مجدد \LTRfootnote{rescaling} به بردارهای فعال‌سازی \LTRfootnote{activations} در معماری ترنسفورمر اضافه می‌کند. این بردارهای آموخته‌شده، برخی از ویژگی‌های داخلی مدل را تقویت \LTRfootnote{amplify} و برخی دیگر را تضعیف \LTRfootnote{inhibit} می‌کنند تا رفتار مدل را برای وظیفه جدید تنظیم کنند.
                \item ویژگی متمایز: این روش تعداد پارامترهای بسیار ناچیزی را آموزش می‌دهد، زیرا فقط بردارهای مقیاس‌دهی را یاد می‌گیرد نه ماتریس‌های کامل را.
            \end{itemize}
            ویژگی کلیدی هر دو روش که این مقاله بر آن تمرکز دارد، ماژولار بودن آن‌هاست. از آنجایی که تغییرات در یک ماژول کوچک و جداگانه ذخیره می‌شود، می‌توان این ماژول‌ها را با استفاده از عملیات ساده حسابی (مانند جمع و تفریق) با یکدیگر ترکیب کرد تا بدون نیاز به آموزش، قابلیت‌های جدیدی در مدل ایجاد نمود، کاری که با مدل‌های تنظیم دقیق کامل  غیرممکن است. 
        \end{itemize}}
        \item  مقاله نشان می‌دهد که ترکیب ماژول‌های \lr{PEFT} نسبت به استفاده‌ی منفرد از آن‌ها عملکرد بهتری دارد. دلایل این بهبود عملکرد چیست؟ همچنین توضیح دهید چرا در روش پیشنهادی مقاله نیازی به آموزش مجدد ماژول‌ها وجود ندارد.
        
        \textcolor{blue}{
        ترکیب ماژول‌های \lr{PEFT} عملکرد بهتری نسبت به استفاده‌ی منفرد از آن‌ها دارد زیرا این کار باعث تجمیع و یکپارچه‌سازی دانش‌ها و مهارت‌های مختلف می‌شود. به جای داشتن یک مدل متخصص در یک حوزه محدود، با ترکیب ماژول‌ها می‌توان یک مدل جامع‌تر یا با قابلیت جدید و هدفمند ساخت.\\
        دلایل این بهبود عملکرد در مقاله به دو شکل اصلی نشان داده شده است:\\
        \begin{enumerate}
            \item ترکیب برای تعمیم‌پذیری\LTRfootnote{Aggregation of Knowledge}:\\
            وقتی دو ماژول که هر کدام بر روی یک توزیع داده متفاوت (مثلاً یکی روی نظرات مثبت و دیگری روی نظرات منفی) آموزش دیده‌اند با هم ترکیب می‌شوند، ماژول حاصل دانش هر دو را در خود دارد. این ماژول جدید می‌تواند عملکرد بهتری روی یک مجموعه داده کلی که شامل هر دو توزیع است نشان دهد، زیرا توانایی درک هر دو جنبه را پیدا کرده است.\\
            این موضوع به وضوح در بخش ۴.۲ (\lr{Composition for Distribution Generalization}) نشان داده شده است. مقاله می‌گوید: یافته‌های ما نشان می‌دهد که یادگیری ماژولار، امکان یکپارچه‌سازی توانایی‌ها از طریق عمل جمع را فراهم می‌کند.
            \item ایجاد مهارت جدید از طریق قیاس\LTRfootnote{Targeted Skill Creation}:\\
            در سناریوهای پیچیده‌تر، ترکیب ماژول‌ها فراتر از یک میانگین‌گیری ساده است. برای مثال، مقاله نشان می‌دهد که می‌توان مهارت طبقه‌بندی نظرات از یک دامنه (مثل محصولات آمازون) را به دامنه دیگر (مثل رستوران‌های \lr{Yelp}) منتقل کرد. این کار با افزودن مهارت طبقه‌بندی آمازون به "تفاوت زبانی" بین دو دامنه انجام می‌شود. این عمل یک مهارت کاملاً جدید و بهینه‌شده برای دامنه هدف ایجاد می‌کند که از ابتدا وجود نداشت.\\
            این رویکرد در بخش ۴.۵ (\lr{Composition for Domain Transfer}) و با استفاده از "معادله قیاسی"\LTRfootnote{analogy equation} معروف "ملکه = پادشاه + زن - مرد" توضیح داده شده است.\\
            در روش پیشنهادی مقاله نیازی به آموزش مجدد وجود ندارد زیرا این روش بر پایه انجام مستقیم عملیات حسابی (جمع و تفریق) بر روی پارامترهای ماژول‌های از قبل آموزش‌دیده استوار است.\\
            به عبارت دیگر، این فرآیند یک محاسبه است، نه یک فرآیند یادگیری. وقتی دو ماژول با هم ترکیب می‌شوند، پارامترهای آن‌ها (مثلاً ماتریس‌های \lr{A} و \lr{B} در \lr{LoRA}) به صورت عددی با هم جمع یا از هم کم می‌شوند تا پارامترهای ماژول جدید را بسازند. در این میان هیچ‌گونه فرآیند بهینه‌سازی، تابع هزینه\LTRfootnote{loss function} یا پس‌انتشار\LTRfootnote{backpropagation} وجود ندارد. تمام دانش لازم از قبل در ماژول‌های اولیه موجود است و  فقط آن‌ها به شیوه‌ای هوشمندانه در کنار هم قرار داده می شوند. 
        \end{enumerate}}
        \item طبق یافته‌های مقاله، چرا ترکیب  \lr{PEM}هایی که با مقداردهی اولیه متفاوت آموزش دیده‌اند، ممکن است منجر به کاهش کارایی مدل ترکیبی شود؟ 

        \textcolor{blue}{
        طبق یافته‌های مقاله، ترکیب \lr{PEM} هایی که با مقداردهی اولیه متفاوت آموزش دیده‌اند ممکن است به کاهش کارایی منجر شود، زیرا مقداردهی اولیه متفاوت باعث می‌شود که هر ماژول در طی آموزش، یک مسیر منحصربه‌فرد را طی کند و در نهایت در یک حوضچه خطا\lr{loss basin} متفاوت در فضای پارامترها قرار بگیرد.
        }
        \item مقاله چگونه نشان می‌دهد که ترکیب  \lr{PEM}ها در فضای وزن می‌تواند منجر به عملکردی فراتر از حالت تک‌وظیفه‌ای شود؟ با استناد به جدول‌ها یا نمودارهای مقاله، توضیح دهید که این ترکیب چگونه موجب تعمیم بهتر به وظایف یا داده‌های جدید می‌شود.

        \textcolor{blue}{
        مقاله با ارائه سناریوهایی که در آن‌ها ترکیب \lr{PEM} ها منجر به خلق قابلیت‌های جدید یا بهبود چشمگیر در تعمیم‌پذیری می‌شود، نشان می‌دهد که این روش فراتر از یک مدل تک وظیفه‌ای ساده عمل می‌کند. روش پیشنهادی مقاله می‌تواند مهارتی کاملاً جدید را بدون آموزش مستقیم بسازد.\\
        این موضوع از دو طریق کلیدی نشان داده می‌شود:\\
        \begin{itemize}
            \item ساخت یک مهارت جدید از طریق قیاس: پیشرفته‌ترین نمونه، سناریوی انتقال دامنه است. در این حالت، مقاله یک طبقه‌بند برای نظرات رستوران‌های \lr{Yelp} می‌سازد، در حالی که هیچ داده برچسب‌دار طبقه‌بندی از \lr{Yelp} در اختیار ندارد. این کار با معادله قیاسی زیر انجام می‌شود: 
            $$
            Yelp \text{طبقه‌بند}  = Amazon \text{طبقه‌بند}  + (Amazon \text{زبان}  - Yelp \text{زبان} )
            $$
            \item این عملیات یک مهارت کاملاً جدید (طبقه‌بندی در دامنه \lr{Yelp}) را از ترکیب مهارت‌های موجود «تولید» می‌کند که این توانایی بسیار فراتر از انجام چند وظیفه از پیش تعریف‌شده است.
            \item تجمیع دانش برای تعمیم‌پذیری بهتر :در سناریوی تعمیم توزیع، مقاله دو ماژول را که هر کدام روی بخش خاص و متفاوتی از داده‌ها آموزش دیده‌اند، با هم ترکیب می‌کند. ماژول ترکیبی نهایی، نه تنها هر دو مهارت را دارد، بلکه در مواجهه با داده‌های جدید و جامع، عملکردی بهتر از میانگین دو ماژول اولیه از خود نشان می‌دهد، زیرا به درک کامل‌تری از توزیع کلی داده‌ها دست یافته است.
        \end{itemize}
        این بهبود در تعمیم‌پذیری به وضوح در جدول‌های مقاله قابل مشاهده است:\\
        \begin{itemize}
            \item جدول ۲ (\lr{Table 2 - Composition for Distribution Generalization}): این جدول نتایج ترکیب دو \lr{PEM} را که روی توزیع‌های داده‌ای متفاوت آموزش دیده‌اند، نشان می‌دهد. ستون \lr{Merged PEM} )\lr{PEM} ادغام‌شده(به طور مداوم عملکردی بهتر از میانگین عملکرد دو ماژول تکی دارد. برای مثال، در مجموعه داده \lr{RTE}، ماژول ترکیبی \lr{LoRA} توانسته ۵.۲ واحد بهبود مطلق نسبت به میانگین دو ماژول اولیه کسب کند. این نشان می‌دهد که ماژول ترکیبی به شکل بهتری به توزیع کلی داده‌ها تعمیم یافته است.
            \item جدول ۵ (\lr{Table 5 - Composition for Domain Transfer}): این جدول عملکرد مدل ترکیبی برای طبقه‌بندی در دامنه جدید را با یک "خط پایه انتقال ساده" (\lr{Vanilla Transfer}) مقایسه می‌کند. نتایج نشان می‌دهد که ترکیب حسابی ماژول‌ها توانسته است مهارتی ایجاد کند که به شکل بسیار بهتری به یک وظیفه و دامنه کاملاً جدید تعمیم پیدا می‌کند.
        \end{itemize}
        }
        \item با وجود مزایای ترکیب ماژول‌های \lr{PEFT}، مقاله به چه محدودیت‌هایی در به‌کارگیری این روش در کاربردهای واقعی مدل‌های زبانی بزرگ اشاره می‌کند؟ 

        \textcolor{blue}{
        مقاله با وجود تاکید بر مزایای ترکیب ماژول‌های \lr{PEFT}، به چند محدودیت مهم در به‌کارگیری این روش در کاربردهای واقعی اشاره می‌کند:\\
        \begin{itemize}
            \item به ارث بردن سوگیری‌ها و مشکلات ایمنی: اگر ماژول‌های اولیه‌ای که با هم ترکیب می‌شوند دارای سوگیری\lr{bias} یا مشکلات ایمنی باشند، ماژول ترکیبی نهایی نیز این مشکلات را به ارث خواهد برد. این موضوع در کاربردهای واقعی که ایمنی و انصاف اهمیت بالایی دارد، یک نگرانی جدی است.
            \item ماهیت جعبه-سیاه و ریسک‌های پنهان : مقاله هشدار می‌دهد که حتی پس از «سم‌زدایی» یک مدل با کم کردن یک ماژول سمی، به دلیل ماهیت جعبه-سیاه شبکه‌های عصبی، هیچ تضمینی وجود ندارد که سمی‌بودن به شکل پنهان در بخش‌های دیگر مدل باقی نمانده باشد و در شرایط پیش‌بینی‌نشده بروز نکند.
            \item محدودیت در معماری و مقداردهی اولیه : نویسندگان اذعان می‌کنند که اکثر آزمایش‌هایشان تحت شرایط کنترل‌شده انجام شده است؛ یعنی ماژول‌هایی که با هم ترکیب شده‌اند دارای معماری یکسان و در اغلب موارد مقداردهی اولیه یکسان بوده‌اند. در دنیای واقعی، ممکن است کاربران بخواهند ماژول‌هایی با ساختارهای متفاوت مثلاً ترکیب یک ماژول \lr{LoRA} با یک ماژول \lr{(IA)³} را با هم ادغام کنند که عملکرد روش در این حالت هنوز بررسی نشده است.
            \item نیاز به تنظیم دستی ابرپارامتر\LTRfootnote{Manual Hyperparameter Tuning}: رویکرد پیشنهادی برای یافتن بهترین ترکیب، به تنظیم دستی ابرپارامتر وزن $\lambda$ نیاز دارد. این موضوع فرآیند را از یک راه‌حل ساده و سریع دور کرده و نیازمند آزمایش و تنظیمات اضافی برای رسیدن به نتیجه مطلوب است که در عمل می‌تواند هزینه‌بر باشد.
        \end{itemize}}
    \end{enumerate}
    
    \item \includegraphics[width=1cm]{figs/Forbidden_AI.jpg}
        درمورد روش \lr{MOCO} به سوالات زیر پاسخ دهید(۱۵ نمره).
        
        \textcolor{blue}{\textbf{برای پاسخ این سوال، از پاسخ خانم میاهی نیا و آقای حسین زاده استفاده شده است.}}
        \begin{enumerate}
            \item   انتخاب ضریب تکانه مناسب برای به روز رسانی کدگذارکلید \LTRfootnote{Key Encoder} اهمیت بالایی دارد. دلیل آن چیست؟ اگر این ضریب بیش از حد کوچک یا بزرگ انتخاب شود چه مشکلاتی ایجاد میکند؟
            \textcolor{blue}{در روش \lr{MoCo}، ضریب تکانه نقش مهمی در به‌روزرسانی شبکه \lr{key encoder} دارد، زیرا این شبکه مستقیما آموزش نمیبیند و از طریق میانگین گیری نمایی از پارامترهای شبکه \lr{query} به‌روزرسانی میشود. اگر این ضریب بیش از حد کوچک باشد، شبکه \lr{key encoder} ناپایدار شده و باعث بی اعتباری \lr{key} های قبلی و کاهش دقت مدل میشود. از طرف دیگر، اگر ضریب خیلی بزرگ باشد، به‌روزرسانی شبکه \lr{key} \lr{encoder} بسیار کند شده و از تغییرات مدل عقب میماند، که باعث کاهش سرعت یادگیری و کارایی مدل میشود. بنابراین، انتخاب مناسب این ضریب برای پایداری و کارایی روش بسیار حیاتی است.}
            \item نقش صف نمونه های منفی را در این الگوریتم شرح دهید.
            \textcolor{blue}{
            در الگوریتم \lr{MoCo} صف نمونه‌های منفی نقش کلیدی در آموزش کنتراستیو دارد. این صف شامل ویژگی‌های استخراج شده از تصاویر \lr{key} در مراحل قبلی آموزش است و به عنوان منابع منفی ثابت و متنوع برای مقایسه با نمونه مثبت استفاده میشود. در فرایند آموزش، هدف مدل این است که \lr{embedding} های \lr{query} را به نمونه مثبتش نزدیک کرده و از نمونه‌های منفی متمایز کند. برای انجام این کار به تعداد زیادی نمونه منفی نیاز است، اما بارگذاری و پردازش همزمان آنها از نظر حافظه دشوار است. \lr{MoCo} این مشکل را با استفاده از یک صف حافظه چرخشی حل میکند: پس از هر مرحله، ویژگی کلید جدید به صف افزوده میشود و قدیمی ترین نمونه حذف میگردد. بنابراین، این صف باعث میشود که بدون نیاز به پردازش همزمان حجم زیادی از داده‌ها، مدل همیشه به مجموعه‌ای بزرگ و به‌روز از نمونه‌های منفی دسترسی داشته باشد و بتواند آموزش کنتراستیو مؤثر و پایدار انجام دهد.
            }
            \item    فرض کنید میخواهیم برای مسئله دسته بندی تصاویر \lr{MRI}، از روش \lr{MOCO} برای یادگیری بازنمایی استفاده کنیم.  با توجه به  اینکه تعداد تصاویر بدون  برچسب فقط 2000 نمونه است، یادگیری بازنمایی به خوبی انجام نمی شود. اگر با استفاده از تکنیک های داده افزایی، از هر نمونه تعداد 10 نمونه جدید ساخته شود تا در نهایت روش \lr{MOCO} با 22000 نمونه آموزش ببیند،چه  تاثیری خواهد  داشت؟ در نهایت دقت مسئله  دسته بندی چه تغییری خواهد کرد؟
            \textcolor{blue}{
            این روش میتواند به آشفتگی در انتخاب نمونه‌های مثبت یا منفی منجر شود. \lr{MoCo} بر پایه این فرض کار میکند که «دو نما ازیک تصویر»مثبت هستند و «هر چیزدیگر»منفی. اگر همه \lr{augment} هایی یک تصویررا جداگانه به مدل بدهیم، \lr{MoCo} نمیداند که آنها از یک پدرند و برخی از آنها را به عنوان منفی نسبت به هم در صف قرار میدهد؛ پس مدل به جای نزدیک کردن نماهای یکسان، سعی میکند آنها را از هم دور کند.
            }
        \end{enumerate}
      	
    \section*{سوالات عملی} 
    \item \includegraphics[width=1cm]{figs/Allowed_with_contributino.jpg}
    در این سوال قصد داریم به قابلیت دسته بندی بدون نمونه در مدل \lr{Clip} بپردازیم. بدین منظور از کتابخانه \href{https://github.com/mlfoundations/open_clip}{\lr{open-clip}} استفاده میکنیم.(۳۰ نمره)
    \begin{enumerate}
        \item ابتدا نسخه \lr{ConvNext-Base} را فراخوانی کنید. سپس از دیتاست \href{https://huggingface.co/datasets/maurice-fp/stanford-dogs}{\lr{Stanford-dogs}} (مجموعه آزمون)برای ارزیابی توانایی یادگیری بدون نمونه این مدل بهره بجویید. برای انتخاب قالب پرامپت متن مجاز هستید از یک قالب دلخواه استفاده کنید.
        \item چند قالب متن دیگر را به دلخواه امتحان کنید و نتایج آنها را مقایسه کنید. توجه داشته باشید، به علت تعداد بالای کلاس های مجموعه داده، انتخاب قالب های متفاوت برای کلاس های مختلف عملی به نظر نمیرسد.
        \item \lr{accuracy}، \lr{precision} ،\lr{recall} و \lr{F1} را به تفکیک کلاس گزارش کنید. کلاسی که بدترین \lr{F1} را دارد را اعلام کنید. سعی کنید برای این کلاس قالب های متفاوتی پیدا کنید تا عملکرد مدل درمورد آن کلاس بهبود یابد. نتایج را مقایسه کنید.
        \item برای هر کلاس یک جاگذاری قابل آموزش تعریف کنید و به کمک گرادیان کاهشی آنرا آموزش دهید(مجموعه آموزش). سپس  دقت را روی مجموعه آزمون محاسبه و گزارش کنید.
        \item رمزگذار متن را کنار بگذارید. رمزگذار تصویر را منجمد کرده و یک لایه تمام متصل اضافه کنید. لایه اضافه شده را آموزش دهید(مجموعه آموزش). سپس  دقت را روی مجموعه آزمون محاسبه و گزارش کنید.
        \item اینبار مدل \lr{ConvNext-XXLarge} را فراخوانی کرده و آزمایشهای قسمت الف و ب را با آن تکرار کرده، نتایج را مقایسه کنید.  
    \end{enumerate}
    
    \textcolor{red}{\textbf{توجه: برای گزارش این سوال نتایج را مقایسه، تحلیل و سپس توجیه کنید.}}
    
    \textcolor{blue}{به نوتبوک \lr{Q3.ipynb} مراجعه شود.}
    \item \includegraphics[width=1cm]{figs/Allowed_with_contributino.jpg}
     در این سوال قصد داریم با استفاده از یک مدل زبانی فارسی با \lr{soft prompting}  آشنا شده و سپس به روش‌هایی از \lr{Reasoning} بپردازیم. قسمت های مشخص شده در نوت بوک \lr{LLM.ipynb} را تکمیل کنید(۲۰ نمره).

    \textcolor{blue}{به نوتبوک \lr{Q4.ipynb} مراجعه شود.}
     \item \includegraphics[width=1cm]{figs/Allowed_with_contributino.jpg}
     در این تمرین با استفاده از کتابخانه‌های  \lr{HuggingFace} و \lr{PEFT}، یک مدل \lr{Vision Transformer (ViT)} را روی دیتاست \lr{Food101} آموزش خواهید داد. هدف اصلی استفاده از روش \lr{Low-Rank Adaptation (LoRA)} برای آموزش مؤثرتر و کم‌هزینه‌تر مدل است. لطفا نوتبوک \lr{peft\_lora.ipynb} را کامل کنید(۲۰ نمره).

     \begin{itemize}
         \item داده‌ها را بارگذاری و آماده‌سازی کنید (از دیتاست \lr{food101} استفاده شده است).
         \item     مدل \lr{ViT} را از \lr{HuggingFace} بارگیری کنید.
        \item     با استفاده از \lr{PEFT} و \lr{LoRA}، بخش‌هایی از مدل را قابل آموزش قرار دهید.
        \item     مدل را با استفاده از \lr{Trainer} آموزش دهید.
        \item     در پایان، از مدل آموزش‌دیده برای پیش‌بینی تصویر جدید استفاده کنید.
    
     \end{itemize}
    \textcolor{blue}{به نوتبوک \lr{Q5.ipynb} مراجعه شود.}


\end{enumerate}



\end{document}


